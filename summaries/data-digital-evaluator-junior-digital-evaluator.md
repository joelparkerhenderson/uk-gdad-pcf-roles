Data role: Digital evaluator
- A digital evaluator assesses the design, implementation and outcomes of a digital product or service and whether it delivers value for the public and society. They may also be a member of a government analytical profession where evaluation is a core skill.

In this role, you will:
- work closely with delivery and policy teams
- develop ‘theories of change’ for products and services that explain links between activities, outputs, intended outcomes and unintended effects
- follow established monitoring and evaluation methods and government guidance
- produce evaluation plans
- design quantitative and qualitative research
- collect and analyse data
- communicate findings, including by publishing reports

Role level: Junior digital evaluator
- A junior digital evaluator is an entry-level role. They have an understanding of the role and can show potential.

At this role level, you will:
- support the work of more experienced digital evaluators
- develop your skills through training
- receive guidance from other digital evaluators on how to produce good work

Skill: Communicating analysis and insight
- explain why it's important to clearly communicate findings from analysis
- explain some methods for effectively communicating findings from analysis

Skill: Data ethics and privacy
- explain the importance of using data ethics and privacy in your work
- identify appropriate channels to discuss ethical issues, with support

Skill: Evaluation delivery
- evaluate interventions with support using techniques including process evaluation, impact evaluation, ‘theory of change’, experimentation and economic evaluation
- collect quantitative and qualitative data with support
- analyse and interpret data you have collected and data from other sources with support
- use some analytical approaches, including descriptive and inferential analysis

Skill: Evaluation planning and strategy
- describe how you might work with a stakeholder to understand what they need to evaluate and why
- describe a process for translating stakeholder needs into potential research questions and evaluation approaches
- describe some methods for monitoring and evaluating a product or service

Skill: Monitoring and evaluation across the product life cycle
- describe how evaluation needs and activities vary at different phases of the product life cycle

Skill: Product and service monitoring
- describe what a ‘theory of change’ is
- identify some appropriate stakeholders to involve in developing a theory of change
- describe common issues when measuring performance indicators
- explain the difference between analysis of digital performance and broader monitoring of a product, for example against strategic objectives

Skill: Quality assurance of data and analysis
- describe some basic data issues and how to check that data and analysis look right
- explain the concept of data being fit for purpose, and the context of the data
- describe some methods for preparing data for analysis
- describe quality assurance processes